\documentclass{article}
\usepackage{fullpage}
\usepackage{amsmath,amssymb}
\begin{document}

\section{EI the TPE way}

\begin{align}
    \mathrm{EI}(x; y^{*}) &= \int_{y^{*}}^{\infty} (y - y^{*})p(y|x) dy \\
    &= \int_{y^{*}}^{\infty} (y - y^{*})\frac{p(x|y)p(y)}{\int_{y'}p(x|y')p(y')} dy \\
    &= \frac{\int_{y^{*}}^{\infty} (y - y^{*})p(x|y)p(y) dy}{\int p(x|y')p(y') {dy'}}
\end{align}

The idea of the TPE derivation is to suppose that
$p(x|y)$ has the form of one density $g(x)$ for Good points that are Greater than $y^*$, and
another density $l(x)$ for Lousy points that are Lesser than $y^*$.

With this assumption, lets work on the numerator and denominator separately.
The numerator is proportional to $g(x)$, with a constant of proportionality that depends in some way on $p(y)$ and $y^*$.
\begin{align}
    \int_{y^{*}}^{\infty} (y - y^{*})p(x|y)p(y) dy
    &= \int_{y^{*}}^{\infty} (y - y^{*})g(x)p(y) dy \\
    &= g(x)\int_{y^{*}}^{\infty} (y - y^{*})p(y) dy \\
    &= g(x) C
\end{align}

If we suppose that $y^*$ is chosen to be some $\alpha$'th percentile of values drawn from $p(y)$, then we can rework the denominator as follows:
\begin{align}
    \int p(x|y')p(y') {dy'}
    &= \int_{-\infty}^{y^*}p(x|y')p(y') dy' + \int_{y^*}^{-\infty}p(x|y')p(y') dy' \\
    &= \int_{-\infty}^{y^*}l(x)p(y') dy' + \int_{y^*}^{-\infty}g(x)p(y') dy' \\
    &= l(x)\int_{-\infty}^{y^*}p(y') dy' + g(x)\int_{y^*}^{-\infty}p(y') dy' \\
    &= l(x) \alpha + g(x)(1 - \alpha)
\end{align}

Coming back the development of EI$(x)$, we continue
\begin{align}
\mathrm{EI}(x; y^{*})
    &= \frac{Cg(x)}{\alpha l(x) + (1 - \alpha) g(x)} \\
    &= \frac{\beta}{\frac{l(x)}{g(x)} + \gamma} \\
\beta 
    &= \frac{C}{\alpha} \\
    &= \int_{y^{*}}^{\infty} \frac{(y - y^{*})p(y)}{\alpha} dy \\
\gamma
    &= \frac{1 - \alpha)}{\alpha}.
\end{align}


\section{PEI}

PEI is defined as the product $P(x) EI(x)$, it is expected improvement weighted by a prior belief that $x$ might be the location of the maximum value of $y$.

\begin{align}
\mathrm{PEI}(x; y^{*})
    &= \mathrm{P}(x) \mathrm{EI}(x; y^*) \\
    &= \frac{\mathrm{P}(x)\beta}{\frac{l(x)}{g(x)} + \gamma} \\
    &\propto \frac{\mathrm{P}(x)}{\frac{l(x)}{g(x)} + \gamma}
\end{align}

The PEI selection criterion has the reasonable property of scaling the expected improvement term to lie between 0 and $P(x)/\gamma$.
Critically, this criterion allows for the selection of reasonable points right from the beginning of search (no seeding is necessary)
and allows for progressive exploration of unbounded search spaces (e.g. $x \in \mathbb{R}$).

Making sure some corner cases are treated OK:
\begin{itemize}
\item Asymptotically, $l$ dominates $g$. 
    $\lim_{x \rightarrow \infty} g(x) / l(x) \rightarrow 0$.
    In this case, we have a broad $l$ and a tight $g$. We want to pick a point that optimizes their ratio, and we don't want the P term to interfere.
    This should indeed happen, because the few narrow peaks in $g(x)$ should cause PEI to spike to $P(x)/\gamma$, which is a slowly varying ceiling on what we expect to get.
\item Asymptotically, $g$ dominates $l$.
    $\lim_{x \rightarrow \infty} g(x) / l(x) \rightarrow \infty$.
    In this case, we have a broad $g$ and a tight $l$. We want to pick any point in the space, but just not one close to the small bad zone $l$.
    We find indeed that $\lim_{x \rightarrow \infty} PEI(x) = \frac{P(x)}{\gamma} = 0$.
\end{itemize}


\section{Wrinkles}

\subsection{Estimating \alpha}

One wrinkle in the use of Bayes' Rule for EI is that, we don't actually have a stochastic process in the joint $x, y$ space.
We just have a function $f:x \rightarrow y$.
The idea of a joint density over $x, y$ random variables comes from the thought experiment of imposing a particular sampling distribution over $x$,
and thereby inducing a density $P(x, y)$. 
This is a density whose generative model certainly factorizes most naturally as $P(x)P(y|x)$, but we're free to chop it the other way too.
Anyway, the wrinkle is that $\alpha$ is supposed to be chosen as some percentile of the $P(y)$ marginal of {\em this} original density, from which
we do not actually draw more than one sample as we perform optimization.
The points we draw during optimization are not drawn from $P(x)$, but rather some other implicit sequence of densities that tend
to place more mass on values of $X$ that are close to high-performance areas.
So if we choose the observed $y$ value at the 75'th percentile, then we are, in effect using a value of $\alpha$ that could be anywhere between $.75$ and $1.0$.
Even though we don't know what's our effective $\alpha$, we need to estimate it to figure out what is $\gamma$, and for $\alpha$ close to $1.0$, $\gamma$ is 
in fact enormously sensitive to the value of $\alpha$.
To be most accurate therefore, there should probably be some sort of schedule that moves $\alpha$ from an initial value where it matches the $y^*$ percentile,
to a final value of e.g. .99 where it doesn't grow any further.



\section{A specific example of PEI}

Suppose we have hyperparameters:

\begin{equation}
    X, Y, Z
\end{equation}

The function (f) we want to minimize has the property that Z is only used when
X takes value 1, but X and Y are always used.

We make this aspect of f apparent to the optimization engine by specifying a
sampling space of the form:

\begin{equation}
    \mathrm{P}(Z | X) \mathrm{P}(X) P(Y)
\end{equation}

The semantics of optimization are such that we may ignore the independence
relationships in the prior, and construct densities over the space that are
less independent.


\begin{equation}
    \mathrm{P}(Z | X, Y) \mathrm{P}(X, Y)
\end{equation}


Optimization in the style of TPE requires that we optimize the ratio of two
distributions over the space, which requires that we actually pick forms for
the various terms contributing to the joint distributions.

The nature of choice() nodes is such that by conditional structure, they also
tell us to rule out large parts of the search space (e.g. P(Z | X=0) is
ignored) and we want to retain that.  In this case, we retain that information
by ensuring that P(Z | X, Y) is fixed to the same distribution when X = 0, in
both the "lower" and "upper" distributions.

Priors:
\begin{align}
    P(X) &= \alpha_{x} e^{-a_{x} - b_{x}X} \\
    P(Y) &= \alpha_{y} e^{-a_{y} - b_{y}Y - c_{y}Y^2} \\
    P(Z|X) &= X \alpha_{z} e^{-a_{z} - b_{z}Z - c_{z}Z^2} + (1 - X)
\end{align}


Supposing we had a real-valued Y, and Z and a binary-valued X, we could choose a general exponential-family form for P(X, Y):

\begin{align}
    P_u(X, Y)
    &= \alpha_u e^{ -a_{xyu} -b_{xyu} (X~Y) -(X~Y)'c_{xyu}(X~Y)}
\end{align}

and choose a conditional form for Z so that it is either drawn from a meaningful distribution if X=1,
or a dummy (0, 1) uniform if X = 0.
\begin{align}
    P_u(Z | X, Y)
    &= X \alpha_{zu} e^{-a_{zu} - b_{zu}Z - Z'c_{zu}Z} + (1 - X)
\end{align}


The PEI(x) optimization strategy is to maximize $\mathrm{P}(x) \mathrm{EI}(x)$.

ERROR STARTS HERE (!)

The TPE approach to EI(X) finds that $EI(x) \propto \frac{1}{P_l(x)/p_u(x) + 1}$ or something,
so the following math for folding the prior in is wrong.

Hopefully after fixing this up, the nasty asymptotic instability identified below will go away.

XXX
%In this case the ratio between the lower and upper densities would look
%like:

\begin{align}
    & P(X, Y, Z)\frac{P_u(X, Y, Z)}{P_l(X, Y, Z)}\\
    & P(X) P(Y) P(Z|X) \frac{P_u(X, Y) P_u(Z|X, Y)}{P_l(X, Y) P_l(Z|X, Y)} \\
    %& \frac{P(X)P_u(X)}{P_l(X)} \frac{P(Y)P_u(Y | X)}{P_l(Y | X)} \frac{P(Z|X)P_u(Z|X, Y)}{P_l(Z|X, Y)} \\
    %& \frac{(X p_{x} + (1 - X) (1 - p_{x}))(X p_{ux} + (1 - X) (1 - p_{ux}))}{X p_{lx} + (1 - X) (1 - p_{lx})}
    %\frac{P(Y)P_u(Y | X)}{P_l(Y | X)}
    %\frac{P(Z|X)P_u(Z|X, Y)}{P_l(Z|X, Y)} \\
\end{align}

Derivation of X Y part.
\begin{align}
    \frac{P(X) P(Y) P_u(X, Y)}{P_l(X, Y)}
    &= \frac{
        \alpha_{x} e^{-a_{x} - b_{x}X}
        \alpha_{y} e^{-a_{y} - b_{y}Y - c_{y}Y^2}
        \alpha_u e^{ -a_{xyu} -b_{xyu} (X~Y) -(X~Y)'c_{xyu}(X~Y)}
    }{
        \alpha_l e^{ -a_{xyl} -b_{xyl} (X~Y) -(X~Y)'c_{xyl}(X~Y)}
    } \\
    &= \frac{ \alpha_{x} \alpha_{y} \alpha_u }{ \alpha_l }
    e^{ - (a_{x} a_{y} a_{xyu} -a_{xyl})
        - ((b_{x}~ b_{y}) - b_{xyu} + b_{xyl})(X~Y)
        - (X~Y)'((0~0~0~c_y) + c_{xyu} - c_{xyl})(X~Y)
    }
\end{align}

Unfortunately there is no guarantee that this function actually takes a maximum. If it happens that $c_y + c_{xyu}$ is less than $c_{xyl}$ then it means that the lower distribution is more tightly distributed than the upper one, and consequently there is an axis along which the ratio grows without bound in both directions.
Intuitively this corresponds to the possible, but unusual situation where a small group of points is all bad, and the set of good points has a larger spread. In this situation, the model will generalize that even further-away points from the bad core will be even better... overwhelming the multiplication by $P(x)$ and going out of control.

As soon as the model actually tries one of those far-away points and sees that it's bad, the system will self-correct. Still, it would be nice to not try anything {\em too} crazy.
I think the earliest source of this insanity is that the ratio $P_u / P_l$ is supposed to represent expected improvement.
The problem 
Hacking time.
One totally heuristic option would be to put some bound of e.g. 6$\sigma$ on normally-distributed variables.
Another option

\end{document}


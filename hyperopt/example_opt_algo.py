"""
Example optimization algorithm for hyperopt.

This algorithm is deliberately simple, in order to document
how to write an optimization algorithm.
"""

__authors__ = "James Bergstra"
__license__ = "3-clause BSD License"
__contact__ = "github.com/jaberg/hyperopt"

import logging
import time
from collections import deque

import numpy as np
from scipy.special import erf
import pyll
from pyll import scope
from pyll.stochastic import implicit_stochastic

from .base import BanditAlgo
from .base import STATUS_OK
from .base import miscs_to_idxs_vals
from .base import miscs_update_idxs_vals
from .base import Trials
import rand

logger = logging.getLogger(__name__)


def make_suggest_many_from_suggest_one(suggest_one):
    """
    Decorator to turn a suggest() function that makes a single prediction
    into one that makes N predictions.

    N predictions are generated by iteratively adding the previous suggested points
    into a temporary Trials object, and feeding that temporary trials object to remaining
    suggest() calls.
    """
    def suggest_many(new_ids, domain, trials, *args, **kwargs):
        if len(new_ids) > 1:
            # -- greedy loop rolling forward
            trials_copy = Trials()
            trials_copy._dynamic_trials = trials.trials
            trials_copy.refresh()
            rval = []
            for new_id in new_ids:
                new_trials1 = suggest_one([new_id], domain, trials_copy,
                        *args, **kwargs)
                trials_copy.insert_trial_docs(new_trials1)
                trials_copy.refresh()
                rval.extend(new_trials1)
            return rval
        else:
            return suggest_one(new_ids, domain, trials, *args, **kwargs)
    suggest_many.__name__ = suggest_one.__name__
    return suggest_many


class expr_evaluator(object):
    def __init__(self, expr,
        deepcopy_inputs=False,
        max_program_len=None,
        memo_gc=True,
        ):
        """
        expr - pyll Apply instance to be evaluated

        memo - optional dictionary of values to use for particular nodes

        deepcopy_inputs - deepcopy inputs to every node prior to calling that
            node's function on those inputs. If this leads to a different return
            value, then some function (XXX add more complete DebugMode
            functionality) in your graph is modifying its inputs and causing
            mis-calculation. XXX: This is not a fully-functional DebugMode because
            if the offender happens on account of the toposort order to be the last
            user of said input, then it will not be detected as a potential
            problem.

        """
        self.expr = pyll.as_apply(expr)
        if deepcopy_inputs not in (0, 1, False, True):
            # -- I've been calling rec_eval(expr, memo) by accident a few times
            #    this error would have been appreciated.
            raise ValueError('deepcopy_inputs should be bool', deepcopy_inputs)
        self.deepcopy_inputs = deepcopy_inputs
        if max_program_len == None:
            self.max_program_len = pyll.base.DEFAULT_MAX_PROGRAM_LEN
        else:
            self.max_program_len = max_program_len
        self.memo_gc = memo_gc

    def eval_nodes(self, memo=None):
        if memo is None:
            memo = {}
        else:
            memo = dict(memo)

        # TODO: optimize dfs to not recurse past the items in memo
        #       this is especially important for evaluating Lambdas
        #       which cause rec_eval to recurse
        #
        # N.B. that Lambdas may expand the graph during the evaluation
        #      so that this iteration may be an incomplete
        if self.memo_gc:
            clients = self.clients = {}
            for aa in pyll.dfs(self.expr):
                clients.setdefault(aa, set())
                for ii in aa.inputs():
                    clients.setdefault(ii, set()).add(aa)

        todo = deque([self.expr])
        while todo:
            if len(todo) > self.max_program_len:
                raise RuntimeError('Probably infinite loop in document')
            node = todo.pop()

            if node in memo:
                # -- we've already computed this, move on.
                continue

            # -- different kinds of nodes are treated differently:
            if node.name == 'switch':
                waiting_on = self.on_switch(memo, node)
                if waiting_on is None:
                    continue
            elif isinstance(node, pyll.Literal):
                # -- constants go straight into the memo
                self.set_memo(memo, node, node.obj)
                continue
            else:
                # -- normal instruction-type nodes have inputs
                waiting_on = [v for v in node.inputs() if v not in memo]

            if waiting_on:
                # -- Necessary inputs have yet to be evaluated.
                #    push the node back in the queue, along with the
                #    inputs it still needs
                todo.append(node)
                todo.extend(waiting_on)
            else:
                rval = self.on_node(memo, node)
                if isinstance(rval, pyll.Apply):
                    # -- if an instruction returns a Pyll apply node
                    # it means evaluate that too. Lambdas do this.
                    #
                    # XXX: consider if it is desirable, efficient, buggy
                    #      etc. to keep using the same memo dictionary
                    foo = rec_eval(rval, deepcopy_inputs, memo,
                            memo_gc=memo_gc)
                    self.set_memo(memo, node, foo)
                else:
                    self.set_memo(memo, node, rval)
        return memo

    def set_memo(self, memo, k, v):
        if self.memo_gc:
            assert v is not pyll.base.GarbageCollected
            memo[k] = v
            for ii in k.inputs():
                # -- if all clients of ii are already in the memo
                #    then we can free memo[ii] by replacing it
                #    with a dummy symbol
                if all(iic in memo for iic in self.clients[ii]):
                    #print 'collecting', ii
                    memo[ii] = pyll.base.GarbageCollected
        else:
            memo[k] = v

    def on_switch(self, memo, node):
        # -- switch is the conditional evaluation node
        switch_i_var = node.pos_args[0]
        if switch_i_var in memo:
            switch_i = memo[switch_i_var]
            try:
                int(switch_i)
            except:
                raise TypeError('switch argument was', switch_i)
            if switch_i != int(switch_i) or switch_i < 0:
                raise ValueError('switch pos must be positive int',
                        switch_i)
            rval_var = node.pos_args[switch_i + 1]
            if rval_var in memo:
                self.set_memo(memo, node, memo[rval_var])
                return 
            else:
                return [rval_var]
        else:
            return [switch_i_var]

    def on_node(self, memo, node):
        # -- not waiting on anything;
        #    this instruction can be evaluated.
        args = _args = [memo[v] for v in node.pos_args]
        kwargs = _kwargs = dict([(k, memo[v])
            for (k, v) in node.named_args])

        if self.memo_gc:
            for aa in args + kwargs.values():
                assert aa is not pyll.base.GarbageCollected

        if self.deepcopy_inputs:
            args = copy.deepcopy(_args)
            kwargs = copy.deepcopy(_kwargs)

        return scope._impls[node.name](*args, **kwargs)


class suggest_algo(expr_evaluator):
    def __init__(self, domain, trials):
        expr_evaluator.__init__(self, domain.s_idxs_vals)
        self.domain = domain
        self.trials = trials

    def __call__(self, new_id):
        memo = self.eval_nodes(
            memo={self.domain.s_new_ids: [new_id]})
        idxs, vals = memo[self.expr]
        new_result = self.domain.new_result()
        new_misc = dict(
            tid=new_id,
            cmd=self.domain.cmd,
            workdir=self.domain.workdir)
        miscs_update_idxs_vals([new_misc], idxs, vals)
        rval = self.trials.new_trial_docs(
            [new_id], [None], [new_result], [new_misc])
        return rval


class TopShuffleAlgo(suggest_algo):
    """
    The top-shuffle algorithm is to make suggestions by choosing randomly among the values for
    each variable, as they occur among the top N trials. It is a simple genetic search
    strategy. Variation is introduced into the top N trials by drawing new values from the
    prior from time to time.
    """
    def __init__(self, domain, trials,
            top_N=5,
            p_prior=0.1):
        suggest_algo.__init__(self, domain, trials)
        self.top_N = top_N
        self.p_prior = p_prior
        print 'new call'
        self.hyper_params = self.domain.vh.vals_by_label().values()
        #print self.domain.vh.vals_by_label()

    def on_node(self, memo, node):
        if node in self.hyper_params:
            print '  ', node.name
        return suggest_algo.on_node(self, memo, node)


@make_suggest_many_from_suggest_one
def suggest(new_ids, domain, trials, *args, **kwargs):
    new_id, = new_ids
    return TopShuffleAlgo(domain, trials, *args, **kwargs)(new_id)
